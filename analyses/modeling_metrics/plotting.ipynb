{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('../../data/replogle22/replogle22_processed.h5ad'):\n",
    "    os.system('aws s3 cp s3://shift-personal-dev/henry/icml_data/replogle22/replogle22_processed.h5ad ../../data/replogle22/replogle22_processed.h5ad')\n",
    "\n",
    "if not os.path.exists('../../data/replogle22/replogle22_names_df_vsrest.pkl'):\n",
    "    os.system('aws s3 cp s3://shift-personal-dev/henry/icml_data/replogle22/replogle22_names_df_vsrest.pkl ../../data/replogle22/replogle22_names_df_vsrest.pkl')\n",
    "\n",
    "if not os.path.exists('../../data/replogle22/replogle22_scores_df_vsrest.pkl'):\n",
    "    os.system('aws s3 cp s3://shift-personal-dev/henry/icml_data/replogle22/replogle22_scores_df_vsrest.pkl ../../data/replogle22/replogle22_scores_df_vsrest.pkl')\n",
    "\n",
    "if not os.path.exists('../../data/gears_predictions.pkl'):\n",
    "    os.system('aws s3 cp s3://shift-personal-dev/lucas/icml/gears_predictions.pkl ../../data/gears_predictions.pkl')\n",
    "\n",
    "if not os.path.exists('../../data/scgpt_predictions.pkl'):\n",
    "    os.system('aws s3 cp s3://shift-personal-dev/lucas/icml/scgpt_predictions.pkl ../../data/scgpt_predictions.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read the numpy files\n",
    "try:\n",
    "    names_df_vsrest = np.load('../../data/replogle22/replogle22_names_df_vsrest.pkl', allow_pickle=True)\n",
    "    print(\"Successfully loaded names_df_vsrest\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading names_df_vsrest: {e}\")\n",
    "\n",
    "try:\n",
    "    scores_df_vsrest = np.load('../../data/replogle22/replogle22_scores_df_vsrest.pkl', allow_pickle=True)\n",
    "    print(\"Successfully loaded scores_df_vsrest\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading scores_df_vsrest: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from scipy.stats import ranksums # Added ranksums\n",
    "import scienceplots\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd())) # For finding the 'analyses' package\n",
    "from common import *\n",
    "\n",
    "\n",
    "DATASET_NAME = 'replogle22'\n",
    "\n",
    "# Initialize analysis using the common function\n",
    "(\n",
    "    adata,\n",
    "    pert_means, # This is the dictionary from get_pert_means(adata) \n",
    "    total_mean_original,\n",
    "    ctrl_mean_original,\n",
    "    DATASET_NAME,\n",
    "    DATASET_CELL_COUNTS,\n",
    "    DATASET_PERTS_TO_SWEEP,\n",
    "    dataset_specific_subdir, # e.g. \"norman19\" or \"replogle22\"\n",
    "    DATA_CACHE_DIR, # Base cache dir, e.g., \"../../../data/\"\n",
    "    original_np_random_state,\n",
    "    ANALYSIS_DIR,\n",
    "    pert_normalized_abs_scores_vsrest,\n",
    "    pert_counts,\n",
    "    scores_df_vsrest,\n",
    "    names_df_vsrest,\n",
    ") = initialize_analysis(DATASET_NAME, 'modeling_with_gears')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the gears predictions\n",
    "with open('../../data/gears_predictions.pkl', 'rb') as f:\n",
    "    gears_predictions = pickle.load(f)\n",
    "\n",
    "# Load the scGPT predictions\n",
    "with open('../../data/scgpt_predictions.pkl', 'rb') as f:\n",
    "    scgpt_predictions = pickle.load(f)\n",
    "\n",
    "\n",
    "first_half_cells = []\n",
    "second_half_cells = []\n",
    "for pert in tqdm(pert_means.keys(), desc=\"Processing perturbations\"):\n",
    "    # Get all cells for this perturbation\n",
    "    pert_cells = adata.obs[adata.obs['condition'] == pert].index.tolist()\n",
    "    \n",
    "    # Randomly shuffle the cells and split into two halves\n",
    "    np.random.shuffle(pert_cells)\n",
    "    split_idx = len(pert_cells) // 2\n",
    "    first_half_cells.extend(pert_cells[:split_idx])\n",
    "    second_half_cells.extend(pert_cells[split_idx:])\n",
    "\n",
    "adata_first_half = adata[first_half_cells].copy()\n",
    "adata_second_half = adata[second_half_cells].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get means for first half and second half\n",
    "pert_means_first_half = get_pert_means(adata_first_half)\n",
    "total_mean_first_half = np.mean(list(pert_means_first_half.values()), axis=0)\n",
    "pert_means_second_half = get_pert_means(adata_second_half)\n",
    "total_mean_second_half = np.mean(list(pert_means_second_half.values()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries to store the metrics for each perturbation\n",
    "pearson_delta_dict_predictive = {}\n",
    "pearson_delta_degs_dict_predictive = {}\n",
    "mse_dict_predictive = {}\n",
    "wmse_dict_predictive = {}\n",
    "r2_delta_dict_predictive = {}\n",
    "wr2_delta_dict_predictive = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ideal predictive baseline: Tech Duplicate oracle ###\n",
    "# Calculate mean expression for each half\n",
    "first_half_mean = adata_first_half[adata_first_half.obs['condition'] == pert].X.mean(axis=0).A1\n",
    "second_half_mean = adata_second_half[adata_second_half.obs['condition'] == pert].X.mean(axis=0).A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip 'control' perturbation and focus only on actual perturbations\n",
    "all_perts_for_predictive = [pert for pert in adata.obs['condition'].unique() if pert != 'control' and pert in list(gears_predictions.keys()) and pert in list(scgpt_predictions.keys())] # Added filter for missing GEARS and scGPT perturbations\n",
    "\n",
    "MIN_DEGS_FOR_METRIC = 200\n",
    "\n",
    "for pert in tqdm(all_perts_for_predictive, desc=\"Processing perturbations\"):\n",
    "\n",
    "    ### Ideal predictive baseline: Tech Duplicate oracle ###\n",
    "    # Calculate mean expression for each half\n",
    "    first_half_mean = adata_first_half[adata_first_half.obs['condition'] == pert].X.mean(axis=0).A1\n",
    "    second_half_mean = adata_second_half[adata_second_half.obs['condition'] == pert].X.mean(axis=0).A1\n",
    "\n",
    "    # Get DEG info\n",
    "    current_pert_weights = pert_normalized_abs_scores_vsrest.get(pert)\n",
    "    pert_degs_vsrest = list(set(adata.uns['deg_dict_vsrest'][pert]['up']) | set(adata.uns['deg_dict_vsrest'][pert]['down']))\n",
    "    pert_degs_vsrest_idx = adata.var_names.isin(pert_degs_vsrest)\n",
    "\n",
    "    \n",
    "    # Calculate basic metrics between the two halves\n",
    "    mse_dict_predictive[pert] = mse(first_half_mean, second_half_mean)    \n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        wmse_dict_predictive[pert] = wmse(first_half_mean, second_half_mean, current_pert_weights)\n",
    "    else:\n",
    "        wmse_dict_predictive[pert] = np.nan\n",
    "    \n",
    "    # Calculate delta metrics\n",
    "    delta_first_half = first_half_mean - total_mean_first_half\n",
    "    delta_second_half = second_half_mean - total_mean_first_half\n",
    "    \n",
    "    # Get Pearson delta for all and just DEGs\n",
    "    pearson_delta_dict_predictive[pert] = pearson(delta_second_half, delta_first_half)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        pearson_delta_degs_dict_predictive[pert] = pearson(delta_first_half[pert_degs_vsrest_idx], delta_second_half[pert_degs_vsrest_idx])\n",
    "    else:\n",
    "        pearson_delta_degs_dict_predictive[pert] = np.nan\n",
    "\n",
    "    # Get R2 with and without weights\n",
    "    r2_delta_dict_predictive[pert] = r2_score_on_deltas(delta_second_half, delta_first_half)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        wr2_delta_dict_predictive[pert] = r2_score_on_deltas(delta_second_half, delta_first_half, current_pert_weights)\n",
    "    else:\n",
    "        wr2_delta_dict_predictive[pert] = np.nan\n",
    "\n",
    "    ### Null baseline: Prediction of data mean ###\n",
    "    # Add \"Data Mean\" condition metrics - use total_mean_original\n",
    "    datamean_key = f\"{pert}_datamean\"\n",
    "    \n",
    "    # Calculate basic metrics between data mean and second half\n",
    "    mse_dict_predictive[datamean_key] = mse(total_mean_original, second_half_mean)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        wmse_dict_predictive[datamean_key] = wmse(total_mean_original, second_half_mean, current_pert_weights)\n",
    "    else:\n",
    "        wmse_dict_predictive[datamean_key] = np.nan\n",
    "\n",
    "    \n",
    "    # Delta metrics for data mean condition\n",
    "    # delta_data_mean would be zeros (total_mean_original - total_mean_original)\n",
    "    # So all delta metrics are 0\n",
    "    pearson_delta_dict_predictive[datamean_key] = 0.0  # Explicitly set to 0\n",
    "    pearson_delta_degs_dict_predictive[datamean_key] = 0.0  # Explicitly set to 0\n",
    "    \n",
    "    # Get the R2 and weighted R2 for delta_data_mean\n",
    "    delta_data_mean = total_mean_first_half - total_mean_first_half\n",
    "    delta_second_half = second_half_mean - total_mean_first_half\n",
    "    r2_delta_dict_predictive[datamean_key] = r2_score_on_deltas(delta_second_half, delta_data_mean)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        wr2_delta_dict_predictive[datamean_key] = r2_score_on_deltas(delta_second_half, delta_data_mean, current_pert_weights)\n",
    "    else:\n",
    "        wr2_delta_dict_predictive[datamean_key] = np.nan\n",
    "\n",
    "\n",
    "    ### Control baseline: Prediction of control mean ###\n",
    "    # Add \"Control\" condition metrics - use control mean instead of first half\n",
    "    control_key = f\"{pert}_control\"\n",
    "    \n",
    "    # Calculate basic metrics between control mean and second half\n",
    "    mse_dict_predictive[control_key] = mse(ctrl_mean_original, second_half_mean)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        wmse_dict_predictive[control_key] = wmse(ctrl_mean_original, second_half_mean, current_pert_weights)\n",
    "    else:\n",
    "        wmse_dict_predictive[control_key] = np.nan\n",
    "    \n",
    "    # Calculate delta metrics\n",
    "    delta_control = ctrl_mean_original - total_mean_first_half\n",
    "    delta_second_half = second_half_mean - total_mean_first_half\n",
    "    \n",
    "    # Get Pearson delta for all and just DEGs\n",
    "    pearson_delta_dict_predictive[control_key] = pearson(delta_control, delta_second_half)\n",
    "    pert_degs_vsrest = list(set(adata.uns['deg_dict_vsrest'][pert]['up']) | set(adata.uns['deg_dict_vsrest'][pert]['down']))\n",
    "    pert_degs_vsrest_idx = adata.var_names.isin(pert_degs_vsrest)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        pearson_delta_degs_dict_predictive[control_key] = pearson(delta_control[pert_degs_vsrest_idx], delta_second_half[pert_degs_vsrest_idx])\n",
    "    else:\n",
    "        pearson_delta_degs_dict_predictive[control_key] = np.nan\n",
    "    \n",
    "    # Get R2 with and without weights\n",
    "    r2_delta_dict_predictive[control_key] = r2_score_on_deltas(delta_second_half, delta_control)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        wr2_delta_dict_predictive[control_key] = r2_score_on_deltas(delta_second_half, delta_control, current_pert_weights)\n",
    "    else:\n",
    "        wr2_delta_dict_predictive[control_key] = np.nan\n",
    "\n",
    "    ### GEARS: Prediction of unseen single genes  ###\n",
    "    gears_key = f\"{pert}_gears\"\n",
    "\n",
    "    gears_mean = gears_predictions.get(pert)\n",
    "    \n",
    "    # Calculate basic metrics between control mean and second half\n",
    "    mse_dict_predictive[gears_key] = mse(gears_mean, second_half_mean)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        wmse_dict_predictive[gears_key] = wmse(gears_mean, second_half_mean, current_pert_weights)\n",
    "    else:\n",
    "        wmse_dict_predictive[gears_key] = np.nan\n",
    "    \n",
    "    # Calculate delta metrics\n",
    "    delta_gears = gears_mean - total_mean_first_half\n",
    "    delta_second_half = second_half_mean - total_mean_first_half\n",
    "    \n",
    "    # Get Pearson delta for all and just DEGs\n",
    "    pearson_delta_dict_predictive[gears_key] = pearson(delta_gears, delta_second_half)\n",
    "    pert_degs_vsrest = list(set(adata.uns['deg_dict_vsrest'][pert]['up']) | set(adata.uns['deg_dict_vsrest'][pert]['down']))\n",
    "    pert_degs_vsrest_idx = adata.var_names.isin(pert_degs_vsrest)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        pearson_delta_degs_dict_predictive[gears_key] = pearson(delta_gears[pert_degs_vsrest_idx], delta_second_half[pert_degs_vsrest_idx])\n",
    "    else:\n",
    "        pearson_delta_degs_dict_predictive[gears_key] = np.nan\n",
    "    \n",
    "    # Get R2 with and without weights\n",
    "    r2_delta_dict_predictive[gears_key] = r2_score_on_deltas(delta_second_half, delta_gears)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        wr2_delta_dict_predictive[gears_key] = r2_score_on_deltas(delta_second_half, delta_gears, current_pert_weights)\n",
    "    else:\n",
    "        wr2_delta_dict_predictive[gears_key] = np.nan\n",
    "\n",
    "    ### scGPT: Prediction of unseen single genes  ###\n",
    "    # Add \"Control\" condition metrics - use control mean instead of first half\n",
    "    scgpt_key = f\"{pert}_scgpt\"\n",
    "\n",
    "    scgpt_mean = scgpt_predictions.get(pert)\n",
    "    \n",
    "    # Calculate basic metrics between control mean and second half\n",
    "    mse_dict_predictive[scgpt_key] = mse(scgpt_mean, second_half_mean)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        wmse_dict_predictive[scgpt_key] = wmse(scgpt_mean, second_half_mean, current_pert_weights)\n",
    "    else:\n",
    "        wmse_dict_predictive[scgpt_key] = np.nan\n",
    "    \n",
    "    # Calculate delta metrics\n",
    "    delta_control = second_half_mean - total_mean_original\n",
    "    delta_scgpt = scgpt_mean - total_mean_original\n",
    "    \n",
    "    # Get Pearson delta for all and just DEGs\n",
    "    pearson_delta_dict_predictive[scgpt_key] = pearson(delta_scgpt, delta_second_half)\n",
    "    pert_degs_vsrest = list(set(adata.uns['deg_dict_vsrest'][pert]['up']) | set(adata.uns['deg_dict_vsrest'][pert]['down']))\n",
    "    pert_degs_vsrest_idx = adata.var_names.isin(pert_degs_vsrest)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        pearson_delta_degs_dict_predictive[scgpt_key] = pearson(delta_scgpt[pert_degs_vsrest_idx], delta_second_half[pert_degs_vsrest_idx])\n",
    "    else:\n",
    "        pearson_delta_degs_dict_predictive[scgpt_key] = np.nan\n",
    "    \n",
    "    # Get R2 with and without weights\n",
    "    r2_delta_dict_predictive[scgpt_key] = r2_score_on_deltas(delta_second_half, delta_scgpt)\n",
    "    if pert_degs_vsrest_idx.sum() > MIN_DEGS_FOR_METRIC:\n",
    "        wr2_delta_dict_predictive[scgpt_key] = r2_score_on_deltas(delta_second_half, delta_scgpt, current_pert_weights)\n",
    "    else:\n",
    "        wr2_delta_dict_predictive[scgpt_key] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for the predictive baseline metrics\n",
    "PLOT_DIR = f'{ANALYSIS_DIR}/plots/'\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "\n",
    "# Process data for plotting\n",
    "# Split keys into three groups based on suffix - regular, _control, and _datamean\n",
    "regular_keys = [key for key in mse_dict_predictive.keys() if '_control' not in key and '_datamean' not in key and '_gears' not in key]\n",
    "control_keys = [key for key in mse_dict_predictive.keys() if '_control' in key]\n",
    "datamean_keys = [key for key in mse_dict_predictive.keys() if '_datamean' in key]\n",
    "gears_keys = [key for key in mse_dict_predictive.keys() if '_gears' in key]\n",
    "scgpt_keys = [key for key in mse_dict_predictive.keys() if '_scgpt' in key]\n",
    "\n",
    "# Create restructured dataframes for side-by-side condition comparison\n",
    "# For main metrics\n",
    "data_for_plotting = []\n",
    "\n",
    "# Process MSE\n",
    "for key in regular_keys:\n",
    "    base_pert = key\n",
    "    control_key = f\"{base_pert}_control\"\n",
    "    datamean_key = f\"{base_pert}_datamean\"\n",
    "    gears_key = f\"{base_pert}_gears\"\n",
    "    scgpt_key = f\"{base_pert}_scgpt\"\n",
    "    \n",
    "    if control_key in control_keys and datamean_key in datamean_keys and gears_key in gears_keys:\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'MSE',\n",
    "            'Condition': 'Tech Duplicate',\n",
    "            'Value': mse_dict_predictive[key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'MSE',\n",
    "            'Condition': '$\\mu^c$ (ctrl mean)',\n",
    "            'Value': mse_dict_predictive[control_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'MSE',\n",
    "            'Condition': '$\\mu^{all}$ (perts mean)',\n",
    "            'Value': mse_dict_predictive[datamean_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'MSE',\n",
    "            'Condition': 'GEARS',\n",
    "            'Value': mse_dict_predictive[gears_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'MSE',\n",
    "            'Condition': 'scGPT',\n",
    "            'Value': mse_dict_predictive[scgpt_key]\n",
    "        })\n",
    "\n",
    "# Process WMSE\n",
    "for key in regular_keys:\n",
    "    base_pert = key\n",
    "    control_key = f\"{base_pert}_control\"\n",
    "    datamean_key = f\"{base_pert}_datamean\"\n",
    "    gears_key = f\"{base_pert}_gears\"\n",
    "    scgpt_key = f\"{base_pert}_scgpt\"\n",
    "    \n",
    "    if control_key in control_keys and datamean_key in datamean_keys and gears_key in gears_keys:\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'WMSE',\n",
    "            'Condition': 'Tech Duplicate',\n",
    "            'Value': wmse_dict_predictive[key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'WMSE',\n",
    "            'Condition': '$\\mu^c$ (ctrl mean)',\n",
    "            'Value': wmse_dict_predictive[control_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'WMSE',\n",
    "            'Condition': '$\\mu^{all}$ (perts mean)',\n",
    "            'Value': wmse_dict_predictive[datamean_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'WMSE',\n",
    "            'Condition': 'GEARS',\n",
    "            'Value': wmse_dict_predictive[gears_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'WMSE',\n",
    "            'Condition': 'scGPT',\n",
    "            'Value': wmse_dict_predictive[scgpt_key]\n",
    "        })\n",
    "\n",
    "# Process Pearson Delta\n",
    "for key in regular_keys:\n",
    "    base_pert = key\n",
    "    control_key = f\"{base_pert}_control\"\n",
    "    datamean_key = f\"{base_pert}_datamean\"\n",
    "    gears_key = f\"{base_pert}_gears\"\n",
    "    scgpt_key = f\"{base_pert}_scgpt\"\n",
    "    \n",
    "    if control_key in control_keys and datamean_key in datamean_keys and gears_key in gears_keys:\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Pearson Delta',\n",
    "            'Condition': 'Tech Duplicate',\n",
    "            'Value': pearson_delta_dict_predictive[key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Pearson Delta',\n",
    "            'Condition': '$\\mu^c$ (ctrl mean)',\n",
    "            'Value': pearson_delta_dict_predictive[control_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Pearson Delta',\n",
    "            'Condition': '$\\mu^{all}$ (perts mean)',\n",
    "            'Value': pearson_delta_dict_predictive[datamean_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Pearson Delta',\n",
    "            'Condition': 'GEARS',\n",
    "            'Value': pearson_delta_dict_predictive[gears_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Pearson Delta',\n",
    "            'Condition': 'scGPT',\n",
    "            'Value': pearson_delta_dict_predictive[scgpt_key]\n",
    "        })\n",
    "\n",
    "# Process Pearson Delta DEGs\n",
    "for key in regular_keys:\n",
    "    base_pert = key\n",
    "    control_key = f\"{base_pert}_control\"\n",
    "    datamean_key = f\"{base_pert}_datamean\"\n",
    "    gears_key = f\"{base_pert}_gears\"\n",
    "    scgpt_key = f\"{base_pert}_scgpt\"\n",
    "    \n",
    "    if control_key in control_keys and datamean_key in datamean_keys and gears_key in gears_keys:\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Pearson Delta DEGs',\n",
    "            'Condition': 'Tech Duplicate',\n",
    "            'Value': pearson_delta_degs_dict_predictive[key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Pearson Delta DEGs',\n",
    "            'Condition': '$\\mu^c$ (ctrl mean)',\n",
    "            'Value': pearson_delta_degs_dict_predictive[control_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Pearson Delta DEGs',\n",
    "            'Condition': '$\\mu^{all}$ (perts mean)',\n",
    "            'Value': pearson_delta_degs_dict_predictive[datamean_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Pearson Delta DEGs',\n",
    "            'Condition': 'GEARS',\n",
    "            'Value': pearson_delta_degs_dict_predictive[gears_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Pearson Delta DEGs',\n",
    "            'Condition': 'scGPT',\n",
    "            'Value': pearson_delta_degs_dict_predictive[scgpt_key]\n",
    "        })\n",
    "           \n",
    "# Process R-Squared Delta\n",
    "for key in regular_keys:\n",
    "    base_pert = key\n",
    "    control_key = f\"{base_pert}_control\"\n",
    "    datamean_key = f\"{base_pert}_datamean\"\n",
    "    gears_key = f\"{base_pert}_gears\"\n",
    "    scgpt_key = f\"{base_pert}_scgpt\"\n",
    "    \n",
    "    if control_key in control_keys and datamean_key in datamean_keys and gears_key in gears_keys:\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'R-Squared Delta',\n",
    "            'Condition': 'Tech Duplicate',\n",
    "            'Value': r2_delta_dict_predictive[key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'R-Squared Delta',\n",
    "            'Condition': '$\\mu^c$ (ctrl mean)',\n",
    "            'Value': r2_delta_dict_predictive[control_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'R-Squared Delta',\n",
    "            'Condition': '$\\mu^{all}$ (perts mean)',\n",
    "            'Value': r2_delta_dict_predictive[datamean_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'R-Squared Delta',\n",
    "            'Condition': 'GEARS',\n",
    "            'Value': r2_delta_dict_predictive[gears_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'R-Squared Delta',\n",
    "            'Condition': 'scGPT',\n",
    "            'Value': r2_delta_dict_predictive[scgpt_key]\n",
    "        })\n",
    "\n",
    "# Process weighted R-Squared Delta\n",
    "for key in regular_keys:\n",
    "    base_pert = key\n",
    "    control_key = f\"{base_pert}_control\"\n",
    "    datamean_key = f\"{base_pert}_datamean\"\n",
    "    gears_key = f\"{base_pert}_gears\"\n",
    "    scgpt_key = f\"{base_pert}_scgpt\"\n",
    "    \n",
    "    if control_key in control_keys and datamean_key in datamean_keys and gears_key in gears_keys:\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Weighted R-Squared Delta',\n",
    "            'Condition': 'Tech Duplicate',\n",
    "            'Value': wr2_delta_dict_predictive[key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Weighted R-Squared Delta',\n",
    "            'Condition': '$\\mu^c$ (ctrl mean)',\n",
    "            'Value': wr2_delta_dict_predictive[control_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Weighted R-Squared Delta',\n",
    "            'Condition': '$\\mu^{all}$ (perts mean)',\n",
    "            'Value': wr2_delta_dict_predictive[datamean_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Weighted R-Squared Delta',\n",
    "            'Condition': 'GEARS',\n",
    "            'Value': wr2_delta_dict_predictive[gears_key]\n",
    "        })\n",
    "        data_for_plotting.append({\n",
    "            'Perturbation': base_pert,\n",
    "            'Metric': 'Weighted R-Squared Delta',\n",
    "            'Condition': 'scGPT',\n",
    "            'Value': wr2_delta_dict_predictive[scgpt_key]\n",
    "        })\n",
    "\n",
    "# Create main DataFrame for plotting\n",
    "df_for_plotting = pd.DataFrame(data_for_plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to create comparison violin plots for the three conditions\n",
    "def plot_predictive_conditions_boxplot(df, metric_name, y_label, plot_title, plot_dir, dataset_name, plot_suffix=''):\n",
    "    # Filter for just this metric\n",
    "    df_metric = df[df['Metric'] == metric_name].copy()\n",
    "    \n",
    "    plt.figure(figsize=(8, 7))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Define colors for conditions\n",
    "    condition_colors = {\n",
    "        'Tech Duplicate': 'steelblue',\n",
    "        '$\\mu^c$ (ctrl mean)': 'forestgreen',\n",
    "        '$\\mu^{all}$ (perts mean)': 'indianred',\n",
    "        'GEARS': 'purple',\n",
    "        'scGPT': 'orange' \n",
    "    }\n",
    "    \n",
    "    # Define the condition order as requested\n",
    "    condition_order = ['$\\mu^c$ (ctrl mean)', '$\\mu^{all}$ (perts mean)', 'GEARS', 'scGPT', 'Tech Duplicate']  # Added GEARS to order\n",
    "    \n",
    "    # Create violin plots with conditions side by side\n",
    "    violinplot = sns.violinplot(\n",
    "        x='Condition', \n",
    "        y='Value', \n",
    "        data=df_metric,\n",
    "        palette=condition_colors,\n",
    "        ax=ax,\n",
    "        order=condition_order,\n",
    "        inner='quartile',  # Show quartiles inside the violins\n",
    "        cut=0              # Don't extend beyond observed data\n",
    "    )\n",
    "    \n",
    "    # Add individual points\n",
    "    sns.stripplot(\n",
    "        x='Condition', \n",
    "        y='Value', \n",
    "        data=df_metric,\n",
    "        color='black', \n",
    "        size=3, \n",
    "        alpha=0.3,\n",
    "        ax=ax,\n",
    "        dodge=True,\n",
    "        order=condition_order\n",
    "    )\n",
    "    \n",
    "    # Add mean values for each condition in black, using Greek μ (mu) symbol\n",
    "    for i, condition in enumerate(condition_order):\n",
    "        condition_data = df_metric[df_metric['Condition'] == condition]['Value']\n",
    "        if not condition_data.empty:\n",
    "            median_val = condition_data.median()\n",
    "            mean_val = condition_data.mean()\n",
    "            # if not np.isnan(mean_val):\n",
    "            #     yloc = mean_val * 1.02 if mean_val > -1 else -.94\n",
    "            #     ax.text(\n",
    "            #         i + 0.15, yloc, \n",
    "            #         f'μ: {mean_val:.3f}', \n",
    "            #         color='black',\n",
    "            #         fontweight='bold',\n",
    "            #         ha='left', \n",
    "            #         va='bottom'\n",
    "            #     )\n",
    "            if not np.isnan(median_val):\n",
    "                yloc = median_val * 1.02 if median_val > -1 else -.94\n",
    "                ax.text(\n",
    "                    i + 0.15, yloc, \n",
    "                    f'Med: {median_val:.3f}', \n",
    "                    color='black',\n",
    "                    fontweight='bold',\n",
    "                    ha='left', \n",
    "                    va='bottom',\n",
    "                    fontsize=8  # Added smaller font size\n",
    "                )\n",
    "    \n",
    "    # Add a horizontal line at y=0 for R-squared and Pearson delta plots\n",
    "    if metric_name in ['R-Squared', 'Pearson Delta', \"Pearson Delta DEGs\", 'R-Squared Delta', 'Weighted R-Squared Delta']:\n",
    "        ax.axhline(y=0, color='firebrick', linestyle='--', linewidth=0.8, zorder=20, alpha=0.7)\n",
    "        ax.set_ylim(-1.05, 1.05) # Set Y-axis from -1 to 1, with a little padding\n",
    "\n",
    "        # Count and annotate points below -1 for each condition\n",
    "        for i, condition in enumerate(condition_order):\n",
    "            condition_data = df_metric[df_metric['Condition'] == condition]\n",
    "            num_outliers = (condition_data['Value'] < -1).sum()\n",
    "            if num_outliers > 0:\n",
    "                ax.text(\n",
    "                    i + 0.15, -1, \n",
    "                    f'N < -1: {num_outliers}', \n",
    "                    color='black',\n",
    "                    fontweight='bold',\n",
    "                    ha='left', \n",
    "                    va='bottom',\n",
    "                    fontsize=8  # Added smaller font size to match median labels\n",
    "                )\n",
    "    \n",
    "    # Format plot\n",
    "    plt.title(f'{plot_title} ({dataset_name})', fontsize=14)\n",
    "    plt.ylabel(y_label, fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add count of perturbations\n",
    "    unique_perts = df_metric['Perturbation'].nunique()\n",
    "    \n",
    "    # Incorporate the optional suffix in the filename to differentiate between regular and DEG plots\n",
    "    filename = f\"condition_comparison_{metric_name.lower().replace(' ', '_')}\"\n",
    "    # Check if DEGs name\n",
    "    \n",
    "    if plot_suffix:\n",
    "        filename += f\"_{plot_suffix}\"\n",
    "    plot_path = f\"{plot_dir}/{filename}.pdf\"\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    print(f\"Plot saved to {plot_path}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictive_conditions_boxplot(df_for_plotting, 'MSE', 'MSE (vs Second Half)', 'MSE (vs Second Half)', PLOT_DIR, DATASET_NAME)\n",
    "plot_predictive_conditions_boxplot(df_for_plotting, 'WMSE', 'Weighted MSE (vs Second Half)', 'Weighted MSE (vs Second Half)', PLOT_DIR, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictive_conditions_boxplot(df_for_plotting, 'R-Squared Delta', r'$R^2$ Delta ($\\mu_{total}$ as delta control)', r'$R^2$ Delta (vs Second Half)', PLOT_DIR, DATASET_NAME)\n",
    "plot_predictive_conditions_boxplot(df_for_plotting, 'Weighted R-Squared Delta', r'Weighted $R^2$ Delta ($\\mu_{total}$ as delta control)', r'Weighted $R^2$ Delta (vs Second Half)', PLOT_DIR, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictive_conditions_boxplot(df_for_plotting, 'Pearson Delta', r'Pearson Delta ($\\mu_{total}$ as delta control)', r'Pearson Delta (vs Second Half)', PLOT_DIR, DATASET_NAME)\n",
    "plot_predictive_conditions_boxplot(df_for_plotting, 'Pearson Delta DEGs', r'Pearson Delta DEGs ($\\mu_{total}$ as delta control)', r'Pearson Delta DEGs (vs Second Half)', PLOT_DIR, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the perturbation which has the highest pearson delta DEGs in GEARS predictions\n",
    "# Find the perturbation which has the highest pearson delta DEGs in GEARS predictions\n",
    "gears_pearson_delta_degs = {pert.replace('_gears', ''): value \n",
    "                            for pert, value in pearson_delta_degs_dict_predictive.items() \n",
    "                            if '_gears' in pert and not pd.isna(value)}\n",
    "\n",
    "if gears_pearson_delta_degs:\n",
    "    max_pert_gears = max(gears_pearson_delta_degs, key=gears_pearson_delta_degs.get)\n",
    "    max_value_gears = gears_pearson_delta_degs[max_pert_gears]\n",
    "    print(f\"Perturbation with highest Pearson delta DEGs (GEARS): {max_pert_gears}, Value: {max_value_gears}\")\n",
    "else:\n",
    "    print(\"No GEARS predictions found or all values are NaN.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the corelation plot between the GEARS prediction and ground truth for the selected perturbation\n",
    "if gears_pearson_delta_degs:\n",
    "    # Get the GEARS prediction and ground truth for the best perturbation\n",
    "    selected_pert = max_pert_gears\n",
    "    \n",
    "    # Get GEARS prediction\n",
    "    gears_pred = gears_predictions[selected_pert]\n",
    "    \n",
    "    # Get ground truth (second half mean)\n",
    "    ground_truth = adata_second_half[adata_second_half.obs['condition'] == selected_pert].X.mean(axis=0).A1\n",
    "    \n",
    "    # Get DEGs for this perturbation\n",
    "    pert_degs = list(set(adata.uns['deg_dict_vsrest'][selected_pert]['up']) | \n",
    "                     set(adata.uns['deg_dict_vsrest'][selected_pert]['down']))\n",
    "    pert_degs_idx = adata.var_names.isin(pert_degs)\n",
    "    \n",
    "    # Get weights for this perturbation\n",
    "    current_pert_weights = pert_normalized_abs_scores_vsrest.get(selected_pert)\n",
    "    \n",
    "    # Calculate deltas\n",
    "    delta_gears = gears_pred - total_mean_first_half\n",
    "    delta_ground_truth = ground_truth - total_mean_first_half\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: All genes\n",
    "    ax1.scatter(delta_ground_truth, delta_gears, alpha=0.3, s=1, color='gray', label='All genes')\n",
    "    \n",
    "    # Add diagonal line\n",
    "    lims = [min(ax1.get_xlim()[0], ax1.get_ylim()[0]),\n",
    "            max(ax1.get_xlim()[1], ax1.get_ylim()[1])]\n",
    "    ax1.plot(lims, lims, 'k--', alpha=0.5, zorder=0)\n",
    "    \n",
    "    # Calculate and display correlation and R2\n",
    "    corr_all = pearson(delta_ground_truth, delta_gears)\n",
    "    r2_all = r2_score_on_deltas(delta_ground_truth, delta_gears, current_pert_weights)\n",
    "    ax1.set_xlabel('Ground Truth (Δ Expression)', fontsize=12)\n",
    "    ax1.set_ylabel('GEARS Prediction (Δ Expression)', fontsize=12)\n",
    "    ax1.set_title(f'{selected_pert} - All Genes\\nPearson r = {corr_all:.3f}, R² = {r2_all:.3f}', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: DEGs only\n",
    "    ax2.scatter(delta_ground_truth[pert_degs_idx], delta_gears[pert_degs_idx], \n",
    "                alpha=0.6, s=10, color='darkred', label='DEGs')\n",
    "    \n",
    "    # Add diagonal line\n",
    "    lims = [min(ax2.get_xlim()[0], ax2.get_ylim()[0]),\n",
    "            max(ax2.get_xlim()[1], ax2.get_ylim()[1])]\n",
    "    ax2.plot(lims, lims, 'k--', alpha=0.5, zorder=0)\n",
    "    \n",
    "    # Calculate and display correlation and R2 for DEGs\n",
    "    corr_degs = pearson(delta_ground_truth[pert_degs_idx], delta_gears[pert_degs_idx])\n",
    "    r2_degs = r2_score_on_deltas(delta_ground_truth[pert_degs_idx], delta_gears[pert_degs_idx], \n",
    "                       current_pert_weights[pert_degs_idx])\n",
    "    ax2.set_xlabel('Ground Truth (Δ Expression)', fontsize=12)\n",
    "    ax2.set_ylabel('GEARS Prediction (Δ Expression)', fontsize=12)\n",
    "    ax2.set_title(f'{selected_pert} - DEGs Only ({pert_degs_idx.sum()} genes)\\nPearson r = {corr_degs:.3f}, R² = {r2_degs:.3f}', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f'{PLOT_DIR}/gears_correlation_best_pert_{selected_pert}.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f'{PLOT_DIR}/gears_correlation_best_pert_{selected_pert}.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print additional statistics\n",
    "    print(f\"\\nStatistics for {selected_pert}:\")\n",
    "    print(f\"Number of cells in ground truth: {(adata_second_half.obs['condition'] == selected_pert).sum()}\")\n",
    "    print(f\"Number of DEGs: {pert_degs_idx.sum()}\")\n",
    "    print(f\"MSE (all genes): {mse_dict_predictive[f'{selected_pert}_gears']:.6f}\")\n",
    "    print(f\"WMSE (weighted by DEGs): {wmse_dict_predictive[f'{selected_pert}_gears']:.6f}\")\n",
    "    print(f\"R² (all genes): {r2_all:.6f}\")\n",
    "    print(f\"R² (DEGs only): {r2_degs:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pert = np.random.choice(adata_second_half.obs['condition'].unique())\n",
    "print(f\"Selected perturbation: {selected_pert}\")\n",
    "second_half_mean = adata_second_half[adata_second_half.obs['condition'] == selected_pert].X.mean(axis=0).A1\n",
    "first_half_mean = adata_first_half[adata_first_half.obs['condition'] == selected_pert].X.mean(axis=0).A1\n",
    "\n",
    "\n",
    "# Get DEGs for this perturbation\n",
    "pert_degs = list(set(adata.uns['deg_dict_vsrest'][selected_pert]['up']) | \n",
    "                    set(adata.uns['deg_dict_vsrest'][selected_pert]['down']))\n",
    "pert_degs_idx = adata.var_names.isin(pert_degs)\n",
    "\n",
    "# Get weights for this perturbation\n",
    "current_pert_weights = pert_normalized_abs_scores_vsrest.get(selected_pert)\n",
    "\n",
    "# Calculate deltas\n",
    "delta_first_half = first_half_mean - total_mean_first_half\n",
    "delta_second_half = second_half_mean - total_mean_first_half\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot 1: All genes\n",
    "ax1.scatter(delta_second_half, delta_first_half, alpha=0.3, s=1, color='gray', label='All genes')\n",
    "\n",
    "# Add diagonal line\n",
    "lims = [min(ax1.get_xlim()[0], ax1.get_ylim()[0]),\n",
    "        max(ax1.get_xlim()[1], ax1.get_ylim()[1])]\n",
    "ax1.plot(lims, lims, 'k--', alpha=0.5, zorder=0)\n",
    "\n",
    "# Calculate and display correlation and R2\n",
    "corr_all = pearson(delta_second_half, delta_first_half)\n",
    "r2_all = r2_score_on_deltas(delta_second_half, delta_first_half)\n",
    "r2_all_weighted = r2_score_on_deltas(delta_second_half, delta_first_half, current_pert_weights)\n",
    "ax1.set_xlabel('Second Half (Δ Expression)', fontsize=12)\n",
    "ax1.set_ylabel('First Half (Δ Expression)', fontsize=12)\n",
    "ax1.set_title(f'{selected_pert} - All Genes\\nPearson r = {corr_all:.3f}, R² = {r2_all:.3f}, R² weighted = {r2_all_weighted:.3f}', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: DEGs only\n",
    "ax2.scatter(delta_second_half[pert_degs_idx], delta_first_half[pert_degs_idx], \n",
    "            alpha=0.6, s=10, color='darkred', label='DEGs')\n",
    "\n",
    "# Add diagonal line\n",
    "lims = [min(ax2.get_xlim()[0], ax2.get_ylim()[0]),\n",
    "        max(ax2.get_xlim()[1], ax2.get_ylim()[1])]\n",
    "ax2.plot(lims, lims, 'k--', alpha=0.5, zorder=0)\n",
    "\n",
    "# Calculate and display correlation and R2 for DEGs\n",
    "corr_degs = pearson(delta_second_half[pert_degs_idx], delta_first_half[pert_degs_idx])\n",
    "r2_degs = r2_score_on_deltas(delta_second_half[pert_degs_idx], delta_first_half[pert_degs_idx])\n",
    "r2_degs_weighted = r2_score_on_deltas(delta_second_half[pert_degs_idx], delta_first_half[pert_degs_idx], \n",
    "                    current_pert_weights[pert_degs_idx])\n",
    "ax2.set_xlabel('Second Half (Δ Expression)', fontsize=12)\n",
    "ax2.set_ylabel('First Half (Δ Expression)', fontsize=12)\n",
    "ax2.set_title(f'{selected_pert} - DEGs Only ({pert_degs_idx.sum()} genes)\\nPearson r = {corr_degs:.3f}, R² = {r2_degs:.3f}, R² weighted = {r2_degs_weighted:.3f}', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print additional statistics\n",
    "print(f\"\\nStatistics for {selected_pert}:\")\n",
    "print(f\"Number of cells in ground truth: {(adata_second_half.obs['condition'] == selected_pert).sum()}\")\n",
    "print(f\"Number of DEGs: {pert_degs_idx.sum()}\")\n",
    "print(f\"MSE (all genes): {mse_dict_predictive[f'{selected_pert}_gears']:.6f}\")\n",
    "print(f\"WMSE (weighted by DEGs): {wmse_dict_predictive[f'{selected_pert}_gears']:.6f}\")\n",
    "print(f\"R² (all genes): {r2_all:.6f}\")\n",
    "print(f\"R² (DEGs only): {r2_degs:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
